#!/usr/bin/env python3
"""
äºŒæ®µéšã‚¿ã‚°å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ  - ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ä»•æ§˜ã«å®Œå…¨æº–æ‹ 

ãƒ•ã‚§ãƒ¼ã‚º1: æ–‡å­—èµ·ã“ã—ä»¥å¤–ã®åˆ—ã‚’å…¨ä»¶èª­ã¿è¾¼ã¿ â†’ è¦ç´ åˆ†æã—ã¦ã‚¿ã‚°å€™è£œä½œæˆ
ãƒ•ã‚§ãƒ¼ã‚º2: æ–‡å­—èµ·ã“ã—å«ã‚€åˆ—ã‚’1ä»¶ãšã¤èª­ã¿è¾¼ã¿ â†’ è©³ç´°åˆ†æã—ã¦10-15å€‹ã®ã‚¿ã‚°é¸å®š
"""

import json
import logging
from typing import List, Dict, Any, Set
from collections import Counter
import re

class TwoPhaseTagProcessor:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ä»•æ§˜ã«å®Œå…¨æº–æ‹ ã—ãŸäºŒæ®µéšã‚¿ã‚°å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, ai_handler=None):
        self.ai_handler = ai_handler
        self.logger = logging.getLogger(__name__)
        self.tag_candidates = set()
        
    def phase1_analyze_all_videos_without_transcript(self, all_video_data: List[Dict[str, Any]]) -> Set[str]:
        """
        ãƒ•ã‚§ãƒ¼ã‚º1: æ–‡å­—èµ·ã“ã—ä»¥å¤–ã®åˆ—ã‚’å…¨ä»¶èª­ã¿è¾¼ã¿ã€è¦ç´ åˆ†æã—ã¦ã‚¿ã‚°å€™è£œã‚’ä½œæˆ
        
        Args:
            all_video_data: å…¨å‹•ç”»ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
            
        Returns:
            å…¨ä½“åˆ†æã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸã‚¿ã‚°å€™è£œã®ã‚»ãƒƒãƒˆ
        """
        print(f"\n=== ãƒ•ã‚§ãƒ¼ã‚º1é–‹å§‹: {len(all_video_data)}ä»¶ã®å‹•ç”»ã‚’åˆ†æï¼ˆæ–‡å­—èµ·ã“ã—é™¤å¤–ï¼‰ ===")
        
        # æ–‡å­—èµ·ã“ã—ä»¥å¤–ã®å…¨ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
        combined_data = {
            'all_titles': [],
            'all_skills': [],
            'all_descriptions': [],
            'all_summaries': []
        }
        
        for video in all_video_data:
            # æ–‡å­—èµ·ã“ã—ã¯æ„å›³çš„ã«é™¤å¤–
            title = video.get('title', '').strip()
            skill = video.get('skill', '').strip()
            description = video.get('description', '').strip()
            summary = video.get('summary', '').strip()
            
            if title:
                combined_data['all_titles'].append(title)
            if skill:
                combined_data['all_skills'].append(skill)
            if description:
                combined_data['all_descriptions'].append(description)
            if summary:
                combined_data['all_summaries'].append(summary)
        
        print(f"åé›†ãƒ‡ãƒ¼ã‚¿:")
        print(f"  ã‚¿ã‚¤ãƒˆãƒ«: {len(combined_data['all_titles'])}ä»¶")
        print(f"  ã‚¹ã‚­ãƒ«: {len(combined_data['all_skills'])}ä»¶")
        print(f"  èª¬æ˜æ–‡: {len(combined_data['all_descriptions'])}ä»¶")
        print(f"  è¦ç´„: {len(combined_data['all_summaries'])}ä»¶")
        print(f"  â€»æ–‡å­—èµ·ã“ã—ã¯æ„å›³çš„ã«é™¤å¤–")
        
        # å…¨ä½“è¦ç´ åˆ†æã‚’å®Ÿè¡Œã—ã¦ã‚¿ã‚°å€™è£œã‚’ç”Ÿæˆ
        self.tag_candidates = self._execute_phase1_analysis(combined_data)
        
        print(f"ãƒ•ã‚§ãƒ¼ã‚º1å®Œäº†: {len(self.tag_candidates)}å€‹ã®ã‚¿ã‚°å€™è£œã‚’ç”Ÿæˆ")
        print(f"ã‚¿ã‚°å€™è£œä¾‹: {sorted(list(self.tag_candidates))[:10]}...")
        
        return self.tag_candidates
    
    def _execute_phase1_analysis(self, combined_data: Dict[str, List[str]]) -> Set[str]:
        """ãƒ•ã‚§ãƒ¼ã‚º1ã®è¦ç´ åˆ†æã‚’å®Ÿè¡Œ"""
        
        # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆã—ã¦åˆ†æç”¨ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
        all_titles_text = ' '.join(combined_data['all_titles'])
        all_skills_text = ' '.join(combined_data['all_skills'])
        all_descriptions_text = ' '.join(combined_data['all_descriptions'])
        all_summaries_text = ' '.join(combined_data['all_summaries'])
        
        # AIåˆ†æç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
        phase1_prompt = f"""
ä»¥ä¸‹ã¯å…¨å‹•ç”»ãƒ‡ãƒ¼ã‚¿ã®é›†ç´„æƒ…å ±ã§ã™ã€‚ã“ã®æƒ…å ±ã‚’åˆ†æã—ã¦ã€ã‚¿ã‚°å€™è£œã¨ãªã‚‹æœ‰ç”¨ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
ã“ã‚Œã‚‰ã®ã‚¿ã‚°å€™è£œã¯å¾Œã®ãƒ•ã‚§ãƒ¼ã‚º2ã§å€‹åˆ¥å‹•ç”»ã®è©³ç´°åˆ†æã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚

ã€å…¨å‹•ç”»ã®ã‚¿ã‚¤ãƒˆãƒ«é›†ç´„ã€‘:
{all_titles_text}

ã€å…¨å‹•ç”»ã®ã‚¹ã‚­ãƒ«é›†ç´„ã€‘:
{all_skills_text}

ã€å…¨å‹•ç”»ã®èª¬æ˜æ–‡é›†ç´„ã€‘:
{all_descriptions_text}

ã€å…¨å‹•ç”»ã®è¦ç´„é›†ç´„ã€‘:
{all_summaries_text}

ã€ã‚¿ã‚°å€™è£œæŠ½å‡ºã®åŸºæº–ã€‘:
1. é »å‡ºã™ã‚‹å°‚é–€ç”¨èªãƒ»ãƒ“ã‚¸ãƒã‚¹ç”¨èª
2. å…·ä½“çš„ãªãƒ„ãƒ¼ãƒ«åãƒ»ã‚µãƒ¼ãƒ“ã‚¹åãƒ»æ‰‹æ³•å
3. æ¥­ç•Œå›ºæœ‰ã®æ¦‚å¿µãƒ»ç†è«–ãƒ»ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
4. æ¸¬å®šå¯èƒ½ãªæŒ‡æ¨™åãƒ»KPI
5. å…·ä½“çš„ãªãƒ—ãƒ­ã‚»ã‚¹åãƒ»æ‰‹é †å
6. è·ç¨®ãƒ»æ¥­ç•Œãƒ»åˆ†é‡å

ã€çµ¶å¯¾ã«é¿ã‘ã‚‹ã¹ãæ±ç”¨èªã€‘:
- ã€Œè¦ç´ ã€ã€Œåˆ†é¡ã€ã€Œãƒã‚¤ãƒ³ãƒˆã€ã€Œæ‰‹æ³•ã€ã€Œæ–¹æ³•ã€ã€ŒæŠ€è¡“ã€ç­‰ã®å˜ä½“ä½¿ç”¨
- ã€ŒåŸºæœ¬ã€ã€Œå¿œç”¨ã€ã€Œå®Ÿè·µã€ã€Œç†è«–ã€ã€Œæ¦‚è¦ã€ã€Œå…¥é–€ã€ç­‰ã®æŠ½è±¡è¡¨ç¾
- ã€Œ4ã¤ã®ãƒã‚¤ãƒ³ãƒˆã€ã€Œ6ã¤ã®è¦ç´ ã€ã€Œ8ã¤ã®åˆ†é¡ã€ç­‰ã®æ•°å­—+æ±ç”¨èª
- ã€Œæ”¹å–„ã€ã€Œæœ€é©åŒ–ã€ã€Œå¼·åŒ–ã€ã€Œå‘ä¸Šã€ç­‰ã®æ±ç”¨ãƒ—ãƒ­ã‚»ã‚¹èª

ã€é‡è¦ã€‘: å…·ä½“çš„ã§æ¤œç´¢ä¾¡å€¤ã®é«˜ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã¿ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

å‡ºåŠ›: æœ‰ç”¨ãªã‚¿ã‚°å€™è£œã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
"""
        
        if self.ai_handler:
            try:
                print("AIåˆ†æã§ã‚¿ã‚°å€™è£œã‚’ç”Ÿæˆä¸­...")
                candidates = self.ai_handler.call_openai(phase1_prompt)
                if candidates and len(candidates) > 0:
                    # æ±ç”¨ã‚¿ã‚°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é©ç”¨
                    filtered_candidates = self._filter_generic_tags(candidates)
                    print(f"AIåˆ†æ: {len(candidates)}å€‹ â†’ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œ: {len(filtered_candidates)}å€‹")
                    return set(filtered_candidates)
            except Exception as e:
                print(f"AIåˆ†æã‚¨ãƒ©ãƒ¼ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†: {e}")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºåˆ†æ
        return self._extract_candidates_fallback(combined_data)
    
    def _extract_candidates_fallback(self, combined_data: Dict[str, List[str]]) -> Set[str]:
        """AIåˆ†æå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†"""
        candidates = set()
        
        # å„ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã‹ã‚‰ç‰¹å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º
        all_text = ' '.join(
            combined_data['all_titles'] + 
            combined_data['all_skills'] + 
            combined_data['all_descriptions'] + 
            combined_data['all_summaries']
        )
        
        # å…·ä½“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º
        specific_patterns = [
            # ãƒ„ãƒ¼ãƒ«ãƒ»ã‚µãƒ¼ãƒ“ã‚¹å
            r'Google Analytics?', r'Salesforce', r'Instagram', r'Facebook', r'TikTok', r'YouTube', r'Twitter', r'LinkedIn',
            # æŒ‡æ¨™ãƒ»KPI
            r'ROI', r'CPA', r'CPM', r'CTR', r'LTV', r'CAC', r'ROAS', r'KPI', r'OKR',
            # æ‰‹æ³•ãƒ»ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
            r'PDCAã‚µã‚¤ã‚¯ãƒ«', r'PDCA', r'A/Bãƒ†ã‚¹ãƒˆ', r'ã‚¢ã‚¸ãƒ£ã‚¤ãƒ«', r'ãƒªãƒ¼ãƒ³ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—',
            # å°‚é–€ç”¨èª
            r'SEO', r'SEM', r'SNSãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°', r'ãƒ‡ã‚¸ã‚¿ãƒ«ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°', r'ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°'
        ]
        
        for pattern in specific_patterns:
            matches = re.findall(pattern, all_text, re.IGNORECASE)
            for match in matches:
                if len(match) > 2:
                    candidates.add(match)
        
        # 2æ–‡å­—ä»¥ä¸Šã®æ—¥æœ¬èªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºï¼ˆæ±ç”¨èªé™¤å¤–ï¼‰
        japanese_words = re.findall(r'[ã‚-ã‚“]+[ãƒ¼]?[ã‚-ã‚“]*|[ã‚¢-ãƒ³]+[ãƒ¼]?[ã‚¢-ãƒ³]*|[ä¸€-é¾¯]+', all_text)
        for word in japanese_words:
            if len(word) >= 2 and not self._is_generic_word(word):
                candidates.add(word)
        
        return candidates
    
    def _filter_generic_tags(self, tags: List[str]) -> List[str]:
        """æ±ç”¨ã‚¿ã‚°ã‚’å®Œå…¨ã«é™¤å¤–"""
        if not tags:
            return tags
        
        # å³æ ¼ãªæ±ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©
        generic_patterns = [
            # æ•°å­—+æ±ç”¨èªãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆå…¨å½¢å¼ï¼‰
            r'\d+ã¤ã®è¦ç´ ', r'\d+ã¤ã®åˆ†é¡', r'\d+ã¤ã®ãƒã‚¤ãƒ³ãƒˆ', r'\d+ã¤ã®æ‰‹æ³•', r'\d+ã¤ã®ã‚¹ãƒ†ãƒƒãƒ—',
            r'\d+ã¤ã®æ–¹æ³•', r'\d+ã¤ã®æŠ€è¡“', r'\d+ã¤ã®é …ç›®', r'\d+ã¤ã®è¦³ç‚¹', r'\d+ã¤ã®è¦–ç‚¹',
            r'\d+å€‹ã®è¦ç´ ', r'\d+å€‹ã®åˆ†é¡', r'\d+å€‹ã®ãƒã‚¤ãƒ³ãƒˆ', r'\d+å€‹ã®æ‰‹æ³•',
            r'\d+ã®è¦ç´ ', r'\d+ã®åˆ†é¡', r'\d+ã®ãƒã‚¤ãƒ³ãƒˆ', r'\d+ã®æ‰‹æ³•', r'\d+ã®ã‚¹ãƒ†ãƒƒãƒ—',
            r'\d+ã®æ–¹æ³•', r'\d+ã®æŠ€è¡“', r'\d+ã®é …ç›®', r'\d+ã®è¦³ç‚¹', r'\d+ã®è¦–ç‚¹',
            # æ±ç”¨å˜èªï¼ˆå˜ä½“ï¼‰
            r'^è¦ç´ $', r'^åˆ†é¡$', r'^ãƒã‚¤ãƒ³ãƒˆ$', r'^æ‰‹æ³•$', r'^æ–¹æ³•$', r'^æŠ€è¡“$',
            r'^åŸºæœ¬$', r'^å¿œç”¨$', r'^å®Ÿè·µ$', r'^ç†è«–$', r'^æ¦‚è¦$', r'^å…¥é–€$',
            r'^åˆç´š$', r'^ä¸­ç´š$', r'^ä¸Šç´š$', r'^åŸºç¤$', r'^ç™ºå±•$', r'^æ´»ç”¨$',
            r'^ã‚¹ãƒ†ãƒƒãƒ—$', r'^æ®µéš$', r'^é …ç›®$', r'^è¦³ç‚¹$', r'^è¦–ç‚¹$', r'^æ¡ä»¶$',
            # æ±ç”¨ãƒ“ã‚¸ãƒã‚¹ç”¨èª
            r'^æ”¹å–„$', r'^æœ€é©åŒ–$', r'^å¼·åŒ–$', r'^å‘ä¸Š$', r'^æ¨é€²$', r'^å±•é–‹$',
            r'^æ§‹ç¯‰$', r'^ç¢ºç«‹$', r'^è¨­è¨ˆ$', r'^é‹ç”¨$', r'^ç®¡ç†$', r'^åˆ†æ$',
            r'^å®Ÿå‹™ã‚¹ã‚­ãƒ«$', r'^æ€è€ƒæ³•$', r'^æ¥­ç•ŒçŸ¥è­˜$', r'^ãƒ„ãƒ¼ãƒ«æ´»ç”¨$',
            r'^äººæè‚²æˆ$', r'^ã‚¹ã‚­ãƒ«é–‹ç™º$', r'^æˆæœå‘ä¸Š$', r'^åŠ¹ç‡åŒ–$'
        ]
        
        filtered = []
        for tag in tags:
            tag = tag.strip()
            if not tag or len(tag) < 2:
                continue
            
            is_generic = False
            for pattern in generic_patterns:
                if re.match(pattern, tag):
                    print(f"  æ±ç”¨ã‚¿ã‚°ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼: {tag}")
                    is_generic = True
                    break
            
            if not is_generic:
                filtered.append(tag)
        
        return filtered
    
    def _is_generic_word(self, word: str) -> bool:
        """æ±ç”¨èªãƒã‚§ãƒƒã‚¯"""
        generic_words = {
            'è¦ç´ ', 'åˆ†é¡', 'ãƒã‚¤ãƒ³ãƒˆ', 'æ‰‹æ³•', 'æ–¹æ³•', 'æŠ€è¡“', 'åŸºæœ¬', 'å¿œç”¨',
            'å®Ÿè·µ', 'ç†è«–', 'æ¦‚è¦', 'å…¥é–€', 'åˆç´š', 'ä¸­ç´š', 'ä¸Šç´š', 'åŸºç¤',
            'ç™ºå±•', 'æ´»ç”¨', 'ã«ã¤ã„ã¦', 'ã«ã‚ˆã‚‹', 'ãŸã‚ã®', 'ã¨ã¯', 'ã§ã™',
            'æ”¹å–„', 'æœ€é©åŒ–', 'å¼·åŒ–', 'å‘ä¸Š', 'æ¨é€²', 'å±•é–‹', 'æ§‹ç¯‰', 'ç¢ºç«‹',
            'è¨­è¨ˆ', 'é‹ç”¨', 'ç®¡ç†', 'åˆ†æ', 'ã‚¹ãƒ†ãƒƒãƒ—', 'æ®µéš', 'é …ç›®', 'è¦³ç‚¹', 'è¦–ç‚¹'
        }
        return word in generic_words
    
    def phase2_individual_analysis_with_transcript(self, video_data: Dict[str, Any], ai_engine: str = 'openai') -> List[str]:
        """
        ãƒ•ã‚§ãƒ¼ã‚º2: æ–‡å­—èµ·ã“ã—å«ã‚€å€‹åˆ¥å‹•ç”»ã®è©³ç´°åˆ†æã§10-15å€‹ã®ã‚¿ã‚°ã‚’é¸å®š
        
        Args:
            video_data: å€‹åˆ¥å‹•ç”»ãƒ‡ãƒ¼ã‚¿ï¼ˆæ–‡å­—èµ·ã“ã—å«ã‚€ï¼‰
            ai_engine: ä½¿ç”¨ã™ã‚‹AIã‚¨ãƒ³ã‚¸ãƒ³
            
        Returns:
            é¸å®šã•ã‚ŒãŸ10-15å€‹ã®ã‚¿ã‚°ã®ãƒªã‚¹ãƒˆ
        """
        title = video_data.get('title', '')
        print(f"\n=== ãƒ•ã‚§ãƒ¼ã‚º2é–‹å§‹: å€‹åˆ¥åˆ†æ '{title[:30]}...' ===")
        print(f"åˆ©ç”¨å¯èƒ½ã‚¿ã‚°å€™è£œ: {len(self.tag_candidates)}å€‹")
        
        # æ–‡å­—èµ·ã“ã—ã‚’å«ã‚€è©³ç´°åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
        transcript = video_data.get('transcript', '')
        transcript_for_analysis = transcript[:2500] if transcript else ''  # ååˆ†ãªæ–‡å­—æ•°ã‚’ç¢ºä¿
        
        candidates_list = sorted(list(self.tag_candidates))
        candidates_str = ', '.join(candidates_list)
        
        phase2_prompt = f"""
ä»¥ä¸‹ã®å‹•ç”»ã«ã¤ã„ã¦ã€æ‰¿èªã•ã‚ŒãŸã‚¿ã‚°å€™è£œã‹ã‚‰æœ€ã‚‚é©åˆ‡ãªã‚¿ã‚°ã‚’15å€‹é¸æŠã—ã¦ãã ã•ã„ã€‚

ã€å‹•ç”»æƒ…å ±ã€‘:
ã‚¿ã‚¤ãƒˆãƒ«: {video_data.get('title', '')}
ã‚¹ã‚­ãƒ«: {video_data.get('skill', '')}
èª¬æ˜æ–‡: {video_data.get('description', '')}
è¦ç´„: {video_data.get('summary', '')}

ã€æ–‡å­—èµ·ã“ã—å†…å®¹ï¼ˆé‡è¦ï¼‰ã€‘:
{transcript_for_analysis}

ã€æ‰¿èªæ¸ˆã¿ã‚¿ã‚°å€™è£œã€‘:
{candidates_str}

ã€é¸å®šåŸºæº–ï¼ˆå„ªå…ˆé †ä½é †ï¼‰ã€‘:
ğŸ¯ **æœ€å„ªå…ˆ: å·®åˆ¥åŒ–ã¨ç‰¹ç•°æ€§**
1. ã“ã®å‹•ç”»ã§ã—ã‹è¨€åŠã•ã‚Œãªã„å…·ä½“çš„ãªãƒ„ãƒ¼ãƒ«åãƒ»ã‚µãƒ¼ãƒ“ã‚¹åãƒ»æ‰‹æ³•å
2. æ–‡å­—èµ·ã“ã—ã«ç™»å ´ã™ã‚‹å›ºæœ‰åè©ãƒ»æ•°å€¤ãƒ»å…·ä½“çš„äº‹ä¾‹
3. ä»–ã®é¡ä¼¼å‹•ç”»ã§ã¯æ‰±ã‚ã‚Œãªã„å°‚é–€çš„ãªæ¦‚å¿µãƒ»ç†è«–

ğŸ” **ç¬¬2å„ªå…ˆ: æ–‡å­—èµ·ã“ã—ç›´æ¥é–¢é€£æ€§**
4. æ–‡å­—èµ·ã“ã—ã§è¤‡æ•°å›è¨€åŠã•ã‚Œã‚‹é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
5. å‹•ç”»ã®æ ¸å¿ƒå†…å®¹ã‚’è¡¨ã™å°‚é–€ç”¨èª

âš¡ **ç¬¬3å„ªå…ˆ: å®Ÿç”¨æ€§ã¨æ¤œç´¢ä¾¡å€¤**
6. æ¤œç´¢æ™‚ã«æœ‰ç”¨ã§å…·ä½“æ€§ã®é«˜ã„ã‚¿ã‚°
7. å­¦ç¿’è€…ãŒæ±‚ã‚ã‚‹å®Ÿè·µçš„ãªçŸ¥è­˜ã‚’è¡¨ã™ã‚¿ã‚°

ã€çµ¶å¯¾ã«é¿ã‘ã‚‹ã¹ãæ±ç”¨ã‚¿ã‚°ï¼ˆå…·ä½“ä¾‹ï¼‰ã€‘:
âŒ ã€Œãƒ“ã‚¸ãƒã‚¹ã‚¹ã‚­ãƒ«ã€ã€Œãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã€ã€Œå–¶æ¥­ã€ã€Œã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€
âŒ ã€Œãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€ã€Œãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—ã€ã€Œãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆã€ã€Œæˆ¦ç•¥ã€
âŒ ã€Œåˆ†æã€ã€Œæ”¹å–„ã€ã€ŒåŠ¹ç‡åŒ–ã€ã€Œæœ€é©åŒ–ã€ã€Œå‘ä¸Šã€ã€Œå¼·åŒ–ã€
âŒ ã€ŒåŸºæœ¬ã€ã€Œå¿œç”¨ã€ã€Œå®Ÿè·µã€ã€Œç†è«–ã€ã€Œå…¥é–€ã€ã€Œæ¦‚è¦ã€
âŒ ã€Œã‚¹ã‚­ãƒ«é–‹ç™ºã€ã€Œäººæè‚²æˆã€ã€Œæ¥­å‹™æ”¹å–„ã€ã€Œçµ„ç¹”é‹å–¶ã€

ã€å³å®ˆäº‹é …ã€‘:
- æ–°ã—ã„ã‚¿ã‚°ã¯ä½œæˆã›ãšã€æ‰¿èªæ¸ˆã¿å€™è£œã‹ã‚‰ã®ã¿é¸æŠ
- æ–‡å­—èµ·ã“ã—ã«å…¨ãé–¢é€£ã—ãªã„ã‚¿ã‚°ã¯çµ¶å¯¾ã«é¸æŠã—ãªã„
- æ±ç”¨çš„ã™ãã‚‹ã‚¿ã‚°ã¯å·®åˆ¥åŒ–ã®è¦³ç‚¹ã‹ã‚‰é™¤å¤–
- å¿…ãš15å€‹ã®ã‚¿ã‚°ã‚’é¸æŠï¼ˆ12-18å€‹ã®ç¯„å›²ã§èª¿æ•´å¯èƒ½ï¼‰

å‡ºåŠ›: é¸æŠã—ãŸã‚¿ã‚°ã®ã¿ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
"""
        
        if self.ai_handler:
            try:
                print("æ–‡å­—èµ·ã“ã—å«ã‚€è©³ç´°åˆ†æã‚’å®Ÿè¡Œä¸­...")
                selected_tags = self._call_ai_for_phase2(phase2_prompt, ai_engine)
                if selected_tags and len(selected_tags) >= 10:
                    final_tags = selected_tags[:15]  # æœ€å¤§15å€‹ã«åˆ¶é™
                    print(f"ãƒ•ã‚§ãƒ¼ã‚º2å®Œäº†: {len(final_tags)}å€‹ã®ã‚¿ã‚°ã‚’é¸å®š")
                    return final_tags
            except Exception as e:
                print(f"AIåˆ†æã‚¨ãƒ©ãƒ¼ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†: {e}")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
        return self._select_tags_fallback(video_data)
    
    def _call_ai_for_phase2(self, prompt: str, ai_engine: str) -> List[str]:
        """ãƒ•ã‚§ãƒ¼ã‚º2ã®AIåˆ†æã‚’å®Ÿè¡Œ"""
        if ai_engine == 'openai':
            return self.ai_handler.call_openai(prompt)
        elif ai_engine == 'claude':
            return self.ai_handler.call_claude(prompt)
        elif ai_engine == 'gemini':
            return self.ai_handler.call_gemini(prompt)
        else:
            return None
    
    def _select_tags_fallback(self, video_data: Dict[str, Any]) -> List[str]:
        """AIåˆ†æå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†"""
        content = f"{video_data.get('title', '')} {video_data.get('skill', '')} {video_data.get('description', '')} {video_data.get('summary', '')} {video_data.get('transcript', '')}".lower()
        
        selected = []
        for candidate in self.tag_candidates:
            if candidate.lower() in content and len(selected) < 15:
                selected.append(candidate)
        
        # 10å€‹æœªæº€ã®å ´åˆã¯æœ€ä½é™ã®ã‚¿ã‚°ã‚’è¿½åŠ 
        if len(selected) < 10:
            basic_tags = ['ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æ•™è‚²', 'ãƒ“ã‚¸ãƒã‚¹ç ”ä¿®', video_data.get('skill', '')]
            for tag in basic_tags:
                if tag and tag not in selected and len(selected) < 15:
                    selected.append(tag)
        
        return selected[:15]
    
    def execute_complete_two_phase_processing(self, all_video_data: List[Dict[str, Any]], ai_engine: str = 'openai') -> List[Dict[str, Any]]:
        """
        å®Œå…¨ãªäºŒæ®µéšå‡¦ç†ã‚’å®Ÿè¡Œ
        
        Args:
            all_video_data: å…¨å‹•ç”»ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
            ai_engine: ä½¿ç”¨ã™ã‚‹AIã‚¨ãƒ³ã‚¸ãƒ³
            
        Returns:
            ã‚¿ã‚°é¸å®šæ¸ˆã¿ã®å‹•ç”»ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆ
        """
        print(f"\n{'='*60}")
        print(f"äºŒæ®µéšã‚¿ã‚°å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹: {len(all_video_data)}ä»¶ã®å‹•ç”»ã‚’å‡¦ç†")
        print(f"{'='*60}")
        
        # ãƒ•ã‚§ãƒ¼ã‚º1: æ–‡å­—èµ·ã“ã—ä»¥å¤–ã®å…¨ä»¶åˆ†æã§ã‚¿ã‚°å€™è£œç”Ÿæˆ
        self.phase1_analyze_all_videos_without_transcript(all_video_data)
        
        if len(self.tag_candidates) == 0:
            print("âš ï¸ ãƒ•ã‚§ãƒ¼ã‚º1ã§ã‚¿ã‚°å€™è£œãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            return []
        
        # ãƒ•ã‚§ãƒ¼ã‚º2: å€‹åˆ¥å‹•ç”»ã®è©³ç´°åˆ†æï¼ˆæ–‡å­—èµ·ã“ã—å«ã‚€ï¼‰
        results = []
        for i, video in enumerate(all_video_data):
            print(f"\n--- å‹•ç”» {i+1}/{len(all_video_data)} ã‚’å‡¦ç†ä¸­ ---")
            
            selected_tags = self.phase2_individual_analysis_with_transcript(video, ai_engine)
            
            result = video.copy()
            result['selected_tags'] = selected_tags
            result['tag_count'] = len(selected_tags)
            result['processing_method'] = 'two_phase_complete'
            result['phase1_candidates'] = len(self.tag_candidates)
            
            results.append(result)
        
        print(f"\n{'='*60}")
        print(f"äºŒæ®µéšå‡¦ç†å®Œäº†")
        print(f"ãƒ•ã‚§ãƒ¼ã‚º1ç”Ÿæˆå€™è£œ: {len(self.tag_candidates)}å€‹")
        print(f"å¹³å‡é¸å®šã‚¿ã‚°æ•°: {sum(len(r['selected_tags']) for r in results) / len(results):.1f}å€‹/å‹•ç”»")
        print(f"{'='*60}")
        
        return results