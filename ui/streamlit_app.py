"""
Streamlit Web UI for Tag Generator
Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆå‹•ç”»ã‚¿ã‚°ç”Ÿæˆãƒ„ãƒ¼ãƒ«
"""

import streamlit as st
import pandas as pd
import sys
import os
import time
import json
from typing import Dict, List, Any, Optional

# ãƒ‘ã‚¹ã‚’è¿½åŠ ã—ã¦ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from sheets_client_oauth import SheetsClientOAuth, display_oauth_ui
from batch_processor import BatchProcessor
from tag_optimizer import TagOptimizer


def init_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–"""
    if 'spreadsheet_data' not in st.session_state:
        st.session_state.spreadsheet_data = None
    if 'column_mapping' not in st.session_state:
        st.session_state.column_mapping = {}
    if 'processing_results' not in st.session_state:
        st.session_state.processing_results = None
    if 'config' not in st.session_state:
        st.session_state.config = load_config()


def load_config() -> Dict[str, Any]:
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    config_path = os.path.join(os.path.dirname(__file__), '..', 'config', 'settings.json')
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        st.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return {}


def validate_environment():
    """ç’°å¢ƒè¨­å®šã®æ¤œè¨¼"""
    # Google OAuthè¨­å®šã¯optionalï¼ˆã‚¢ãƒ—ãƒªå†…ã§èªè¨¼ã™ã‚‹ï¼‰
    oauth_vars = ['GOOGLE_CLIENT_ID', 'GOOGLE_CLIENT_SECRET']
    missing_oauth = [var for var in oauth_vars if not os.getenv(var)]
    
    if missing_oauth:
        st.warning(f"Google OAuthè¨­å®šãŒä¸å®Œå…¨ã§ã™: {', '.join(missing_oauth)}")
        st.info("Googleèªè¨¼ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€.envãƒ•ã‚¡ã‚¤ãƒ«ã«GOOGLE_CLIENT_IDã¨GOOGLE_CLIENT_SECRETã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    
    return True


def load_spreadsheet_data(sheets_client: SheetsClientOAuth, url: str, sheet_name: str) -> Optional[pd.DataFrame]:
    """ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    try:
        with st.spinner('ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã¿ä¸­...'):
            data = sheets_client.read_spreadsheet(url, sheet_name)
            return data
    except Exception as e:
        st.error(f"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None


def display_column_mapping_ui(df: pd.DataFrame) -> Dict[str, str]:
    """åˆ—ãƒãƒƒãƒ”ãƒ³ã‚°UIã‚’è¡¨ç¤º"""
    st.subheader("ğŸ”§ åˆ—ãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®š")
    st.write("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®åˆ—ã‚’ä»¥ä¸‹ã®é …ç›®ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã—ã¦ãã ã•ã„ï¼š")
    
    columns = [''] + list(df.columns)
    
    mapping = {}
    col1, col2 = st.columns(2)
    
    with col1:
        mapping['title'] = st.selectbox("ğŸ“ å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ« (å¿…é ˆ)", columns, key="title_col")
        mapping['skill'] = st.selectbox("ğŸ¯ ã‚¹ã‚­ãƒ«/ã‚«ãƒ†ã‚´ãƒª", columns, key="skill_col")
        mapping['description'] = st.selectbox("ğŸ“„ å‹•ç”»èª¬æ˜", columns, key="desc_col")
    
    with col2:
        mapping['summary'] = st.selectbox("ğŸ“‹ è¦ç´„", columns, key="summary_col")
        mapping['transcript'] = st.selectbox("ğŸ™ï¸ éŸ³å£°ãƒ†ã‚­ã‚¹ãƒˆ", columns, key="transcript_col")
    
    # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®æ¤œè¨¼
    if not mapping['title']:
        st.warning("âš ï¸ å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ã®åˆ—é¸æŠã¯å¿…é ˆã§ã™")
        return {}
    
    return {k: v for k, v in mapping.items() if v}


def display_ai_selection() -> str:
    """AIé¸æŠUIã‚’è¡¨ç¤º"""
    st.subheader("ğŸ¤– AI ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼é¸æŠ")
    
    # ãƒãƒƒãƒãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã§æ¥ç¶šãƒ†ã‚¹ãƒˆ
    try:
        batch_processor = BatchProcessor()
        connection_status = batch_processor.test_ai_connections()
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            status_icon = "ğŸŸ¢" if connection_status.get('openai', False) else "ğŸ”´"
            st.write(f"{status_icon} OpenAI GPT")
        
        with col2:
            status_icon = "ğŸŸ¢" if connection_status.get('claude', False) else "ğŸ”´"
            st.write(f"{status_icon} Claude")
        
        with col3:
            status_icon = "ğŸŸ¢" if connection_status.get('gemini', False) else "ğŸ”´"
            st.write(f"{status_icon} Google Gemini")
        
        # åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ã¿é¸æŠè‚¢ã«è¡¨ç¤º
        available_providers = [name for name, status in connection_status.items() if status]
        
        if not available_providers:
            st.error("åˆ©ç”¨å¯èƒ½ãªAIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã®APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return ""
        
        provider_map = {
            'openai': 'OpenAI GPT',
            'claude': 'Claude',
            'gemini': 'Google Gemini'
        }
        
        provider_options = [provider_map[p] for p in available_providers]
        selected_display = st.selectbox("ä½¿ç”¨ã™ã‚‹AIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„", provider_options)
        
        # è¡¨ç¤ºåã‹ã‚‰å†…éƒ¨åã«å¤‰æ›
        reverse_map = {v: k for k, v in provider_map.items()}
        return reverse_map[selected_display]
        
    except Exception as e:
        st.error(f"AIæ¥ç¶šãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        return ""


def display_processing_settings() -> Dict[str, Any]:
    """å‡¦ç†è¨­å®šUIã‚’è¡¨ç¤º"""
    st.subheader("âš™ï¸ å‡¦ç†è¨­å®š")
    
    col1, col2 = st.columns(2)
    
    with col1:
        batch_size = st.slider(
            "ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆä¸€åº¦ã«å‡¦ç†ã™ã‚‹å‹•ç”»æ•°ï¼‰",
            min_value=1,
            max_value=50,
            value=10,
            help="å¤§ããã™ã‚‹ã¨ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå¢—åŠ ã—ã¾ã™ãŒã€å‡¦ç†ãŒæ—©ããªã‚Šã¾ã™"
        )
    
    with col2:
        target_tags = st.slider(
            "ç›®æ¨™ã‚¿ã‚°æ•°",
            min_value=100,
            max_value=300,
            value=175,
            help="æœ€çµ‚çš„ã«å‡ºåŠ›ã™ã‚‹ã‚¿ã‚°ã®ç›®æ¨™æ•°"
        )
    
    return {
        'batch_size': batch_size,
        'target_tag_count': target_tags
    }


def estimate_processing_info(total_videos: int, ai_provider: str, batch_size: int):
    """å‡¦ç†æ™‚é–“ãƒ»ã‚³ã‚¹ãƒˆæ¨å®šã‚’è¡¨ç¤º"""
    try:
        batch_processor = BatchProcessor()
        
        # è¨­å®šã‚’ä¸€æ™‚çš„ã«æ›´æ–°
        batch_processor.batch_size = batch_size
        
        time_estimate = batch_processor.estimate_processing_time(total_videos, ai_provider)
        memory_estimate = batch_processor.get_memory_usage_estimate(total_videos)
        
        st.subheader("ğŸ“Š å‡¦ç†æ¨å®šæƒ…å ±")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ç·å‡¦ç†æ™‚é–“", f"{time_estimate['total_minutes']:.1f}åˆ†")
            st.metric("ãƒãƒƒãƒæ•°", f"{time_estimate['total_batches']}")
        
        with col2:
            st.metric("ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡", f"{memory_estimate['batch_mb']:.1f}MB")
            memory_safe = "âœ… å®‰å…¨" if memory_estimate['memory_safe'] else "âš ï¸ è¦æ³¨æ„"
            st.metric("ãƒ¡ãƒ¢ãƒªçŠ¶æ³", memory_safe)
        
        with col3:
            # æ¦‚ç®—ã‚³ã‚¹ãƒˆï¼ˆãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆ¥ï¼‰
            cost_per_video = {'openai': 0.01, 'claude': 0.015, 'gemini': 0.005}
            estimated_cost = total_videos * cost_per_video.get(ai_provider, 0.01)
            st.metric("æ¨å®šã‚³ã‚¹ãƒˆ", f"${estimated_cost:.2f}")
        
        if not memory_estimate['memory_safe']:
            st.warning("âš ï¸ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒåˆ¶é™ã‚’è¶…ãˆã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å°ã•ãã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
            
    except Exception as e:
        st.error(f"å‡¦ç†æ¨å®šã‚¨ãƒ©ãƒ¼: {str(e)}")


def process_videos(
    df: pd.DataFrame,
    ai_provider: str,
    column_mapping: Dict[str, str],
    processing_settings: Dict[str, Any]
) -> Optional[Dict[str, Any]]:
    """å‹•ç”»å‡¦ç†ã‚’å®Ÿè¡Œ"""
    
    try:
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        def progress_callback(progress: float, current: int, total: int):
            progress_bar.progress(progress / 100)
            status_text.text(f"å‡¦ç†ä¸­: {current}/{total} å‹•ç”» ({progress:.1f}%)")
        
        # ãƒãƒƒãƒå‡¦ç†å®Ÿè¡Œ
        status_text.text("ãƒãƒƒãƒå‡¦ç†ã‚’åˆæœŸåŒ–ä¸­...")
        batch_processor = BatchProcessor()
        batch_processor.batch_size = processing_settings['batch_size']
        
        status_text.text("AIå‡¦ç†ã§ã‚¿ã‚°ã‚’ç”Ÿæˆä¸­...")
        all_tags = batch_processor.process_videos_batch(
            df, ai_provider, column_mapping, progress_callback
        )
        
        status_text.text("ã‚¿ã‚°æœ€é©åŒ–ã‚’å®Ÿè¡Œä¸­...")
        progress_bar.progress(90)
        
        # ã‚¿ã‚°æœ€é©åŒ–
        tag_optimizer = TagOptimizer()
        tag_optimizer.target_tag_count = processing_settings['target_tag_count']
        
        final_tags = tag_optimizer.optimize_tags(all_tags, df, column_mapping)
        
        # åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        analytics = tag_optimizer.generate_tag_analytics(final_tags, all_tags)
        
        progress_bar.progress(100)
        status_text.text("âœ… å‡¦ç†å®Œäº†!")
        
        return {
            'all_tags': all_tags,
            'final_tags': final_tags,
            'analytics': analytics,
            'processed_data': df
        }
        
    except Exception as e:
        st.error(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None


def display_results(results: Dict[str, Any]):
    """çµæœã‚’è¡¨ç¤º"""
    st.subheader("ğŸ“ˆ å‡¦ç†çµæœ")
    
    analytics = results['analytics']
    
    # åŸºæœ¬çµ±è¨ˆ
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("æœ€çµ‚ã‚¿ã‚°æ•°", analytics['total_final_tags'])
    
    with col2:
        st.metric("å…ƒã‚¿ã‚°æ•°", analytics['unique_original_tags'])
    
    with col3:
        st.metric("å‰Šæ¸›ç‡", f"{analytics['reduction_ratio']:.1%}")
    
    with col4:
        st.metric("ã‚«ãƒãƒ¬ãƒƒã‚¸", f"{analytics['coverage_percentage']:.1f}%")
    
    # æœ€çµ‚ã‚¿ã‚°è¡¨ç¤º
    st.subheader("ğŸ·ï¸ æœ€çµ‚ã‚¿ã‚°ã‚»ãƒƒãƒˆ")
    
    # ã‚¿ã‚°ã‚’3åˆ—ã§è¡¨ç¤º
    tags = results['final_tags']
    cols = st.columns(3)
    
    for i, tag in enumerate(tags):
        col_idx = i % 3
        with cols[col_idx]:
            st.write(f"â€¢ {tag}")
    
    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™
    tags_df = pd.DataFrame({'tags': tags})
    csv_data = tags_df.to_csv(index=False, encoding='utf-8-sig')
    
    st.download_button(
        label="ğŸ“¥ ã‚¿ã‚°ãƒªã‚¹ãƒˆã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=csv_data,
        file_name=f"optimized_tags_{time.strftime('%Y%m%d_%H%M%S')}.csv",
        mime="text/csv"
    )


def save_to_spreadsheet(results: Dict[str, Any], original_url: str) -> Optional[str]:
    """çµæœã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜"""
    try:
        with st.spinner('Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜ä¸­...'):
            sheets_client = SheetsClient()
            
            # å…ƒãƒ‡ãƒ¼ã‚¿ã«ã‚¿ã‚°åˆ—ã‚’è¿½åŠ 
            df = results['processed_data'].copy()
            all_tags = results['all_tags']
            
            # å„å‹•ç”»ã®ã‚¿ã‚°ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã«å¤‰æ›
            tag_strings = [', '.join(tags) if tags else '' for tags in all_tags]
            df['generated_tags'] = tag_strings
            
            # æœ€çµ‚ã‚¿ã‚°ã‚»ãƒƒãƒˆã‚’åˆ¥ã‚·ãƒ¼ãƒˆã«
            final_tags_df = pd.DataFrame({'optimized_tags': results['final_tags']})
            
            # æ–°ã—ã„ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’ä½œæˆ
            new_url = sheets_client.create_copy_with_tags(original_url, df, final_tags_df)
            
            return new_url
            
    except Exception as e:
        st.error(f"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    st.set_page_config(
        page_title="Tag Generator",
        page_icon="ğŸ·ï¸",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.title("ğŸ·ï¸ å‹•ç”»ã‚¿ã‚°ç”Ÿæˆãƒ„ãƒ¼ãƒ«")
    st.markdown("---")
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹åˆæœŸåŒ–
    init_session_state()
    
    # ç’°å¢ƒè¨­å®šæ¤œè¨¼
    if not validate_environment():
        st.stop()
    
    # Google OAuthèªè¨¼
    sheets_client = display_oauth_ui()
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("ğŸ“‹ å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—")
        st.write("0. Googleèªè¨¼")
        st.write("1. ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆèª­ã¿è¾¼ã¿")
        st.write("2. åˆ—ãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®š")
        st.write("3. AIãƒ»å‡¦ç†è¨­å®š")
        st.write("4. ã‚¿ã‚°ç”Ÿæˆå®Ÿè¡Œ")
        st.write("5. çµæœç¢ºèªãƒ»ä¿å­˜")
    
    # Googleèªè¨¼ãŒå®Œäº†ã—ã¦ã„ã‚‹å ´åˆã®ã¿å‡¦ç†ã‚’ç¶šè¡Œ
    if sheets_client is None:
        st.info("ã¾ãšGoogleèªè¨¼ã‚’å®Œäº†ã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    
    # Step 1: ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆèª­ã¿è¾¼ã¿
    st.header("1ï¸âƒ£ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆèª­ã¿è¾¼ã¿")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        spreadsheet_url = st.text_input(
            "Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®URL",
            placeholder="https://docs.google.com/spreadsheets/d/...",
            help="èªè¨¼æ¸ˆã¿ã®Googleã‚¢ã‚«ã‚¦ãƒ³ãƒˆã§ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ãªã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®URL"
        )
    
    with col2:
        # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆURLãŒå…¥åŠ›ã•ã‚ŒãŸå ´åˆã€åˆ©ç”¨å¯èƒ½ãªã‚·ãƒ¼ãƒˆä¸€è¦§ã‚’å–å¾—
        if spreadsheet_url:
            available_sheets = sheets_client.get_available_sheets(spreadsheet_url)
            if available_sheets:
                sheet_name = st.selectbox("ã‚·ãƒ¼ãƒˆé¸æŠ", available_sheets)
            else:
                sheet_name = st.text_input("ã‚·ãƒ¼ãƒˆå", value="Sheet1")
        else:
            sheet_name = st.text_input("ã‚·ãƒ¼ãƒˆå", value="Sheet1")
    
    if st.button("ğŸ“Š ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆèª­ã¿è¾¼ã¿", type="primary"):
        if spreadsheet_url:
            data = load_spreadsheet_data(sheets_client, spreadsheet_url, sheet_name)
            if data is not None:
                st.session_state.spreadsheet_data = data
                st.success(f"âœ… {len(data)}è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        else:
            st.warning("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
    if st.session_state.spreadsheet_data is not None:
        st.subheader("ğŸ“„ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        st.dataframe(st.session_state.spreadsheet_data.head(), use_container_width=True)
        
        # Step 2: åˆ—ãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®š
        st.header("2ï¸âƒ£ åˆ—ãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®š")
        column_mapping = display_column_mapping_ui(st.session_state.spreadsheet_data)
        
        if column_mapping:
            st.session_state.column_mapping = column_mapping
            
            # Step 3: AIãƒ»å‡¦ç†è¨­å®š
            st.header("3ï¸âƒ£ AIãƒ»å‡¦ç†è¨­å®š")
            
            ai_provider = display_ai_selection()
            
            if ai_provider:
                processing_settings = display_processing_settings()
                
                # å‡¦ç†æ¨å®šæƒ…å ±
                total_videos = len(st.session_state.spreadsheet_data)
                estimate_processing_info(total_videos, ai_provider, processing_settings['batch_size'])
                
                # Step 4: å‡¦ç†å®Ÿè¡Œ
                st.header("4ï¸âƒ£ ã‚¿ã‚°ç”Ÿæˆå®Ÿè¡Œ")
                
                if st.button("ğŸš€ ã‚¿ã‚°ç”Ÿæˆé–‹å§‹", type="primary", use_container_width=True):
                    results = process_videos(
                        st.session_state.spreadsheet_data,
                        ai_provider,
                        column_mapping,
                        processing_settings
                    )
                    
                    if results:
                        st.session_state.processing_results = results
                        st.success("ğŸ‰ ã‚¿ã‚°ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    
    # Step 5: çµæœè¡¨ç¤ºãƒ»ä¿å­˜
    if st.session_state.processing_results is not None:
        st.header("5ï¸âƒ£ çµæœç¢ºèªãƒ»ä¿å­˜")
        
        display_results(st.session_state.processing_results)
        
        # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆä¿å­˜
        st.subheader("ğŸ’¾ Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜")
        
        if st.button("ğŸ“¤ æ–°ã—ã„ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã¨ã—ã¦ä¿å­˜", type="secondary"):
            new_url = save_to_spreadsheet(st.session_state.processing_results, spreadsheet_url)
            if new_url:
                st.success("âœ… ä¿å­˜å®Œäº†!")
                st.markdown(f"**æ–°ã—ã„ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ:** [ã“ã¡ã‚‰ã‚’ã‚¯ãƒªãƒƒã‚¯]({new_url})")


if __name__ == "__main__":
    main()